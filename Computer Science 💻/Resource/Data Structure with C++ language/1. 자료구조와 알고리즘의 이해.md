## 자료구조에 대한 기본적인 이해

<br>

### 자료구조란?

> 데이터 값의 모임, 또 데이터 간의 관계, 그리고 데이터에 적용할 수 있는 함수나 명령을 의미한다

프로그램이란 데이터를 표현하고 그렇게 표현된 데이터를 처리하는 것이라고 했다.

위에서 말하는 ==데이터의 표현은 **데이터의 저장**을 포함하는 개념==이며 이 "**데이터의 저장**"이 자료구조이다.

+ 자료구조의 분류
	  <br>
	+ 선형 구조
		선의 형태로 일렬로 저장되는 방식의 자료구조이다.
		+ 리스트
		+ 스택
		+ 큐
		  <br>
	+ 파일 구조
		파일 또한 데이터를 저장하는 도구이기 때문에 파일이 데이터를 저장하는 구조 또한 자료구조이다.
		+ 순차파일
		+ 색인파일
		+ 직접파일
		  <br>
	+ 비선형 구조
		일렬로 저장되지 않는 자료구조
		+ 트리
		+ 그래프
		  <br>
	+ 단순 구조
		+ 정수
		+ 실수
		+ 문자
		+ 문자열


### 자료 구조와 알고리즘

> 알고리즘이란 표현 및 저장된 데이터를 대상으로 하는 문제의 해결방법

+ 중요한 특징
	
	**자료구조가 결정되어야 비로소 효율적인 알고리즘을 결정할 수 있다.**
	즉, 자료구조를 모르고서 무턱대고 알고리즘만 공부해봐야 제대로 된 문제해결 능력을 함양하기 힘들다.

<br>

## 알고리즘 분석 방법

<br>

### 시간 복잡도, time complexity

> 얼마나 빠르게 알고리즘이 수행되었는지 알고리즘의 수행시간을 분석한 결과

<br>

### 공간 복잡도,  space complexity

> 얼마나 효율적으로 메모리 공간을 적게 쓰고 알고리즘이 수행되었는지 알고리즘의 메모리 사용량을 분석한 결과

+ 복잡도 평가 방법
	1. **연산의 횟수를 카운팅 한다.** 
	2. 처리해야 할 **데이터의 수 `n`에 대한 연산 횟수 함수 `T(n)`을 구성**한다.
	   즉, ==데이터의 수를 입력하면 연산 횟수가 바로 계산이 되는 식을 구성한다는 뜻==이며
	   식을 구성하면 데이터 수의 증가에 따른 연산 횟수의 변화 폭을 판단 할 수 있기 때문이다.
	   즉, ==**식을 구성하면 연산횟수 변화량을 알 수 있다**==는 의미이다.

<br>

+ 예시
```mathpad
%$1:=(1/2)*x+2
%$4:=[(1/2)*x+2]
%$6:=2^x
t(n):=1/2x + 2
t1(n):=2^x
$plot(\mathrm{O2}\left(n\right) , \mathrm{O3}\left(n\right) , \mathrm{O4}\left(n\right) , \mathrm{O5}\left(n\right) , \mathrm{O6}\left(n\right) , \mathrm{O7}\left(n\right) , \left(0 , 10\right))$, [-0.00357,8.13], [-0.00121,12.0])=~?
```
+ 설명
  
	위의 예시는 `y = 연산 횟수 t(n)`, `x = 데이터의 수 n`이다.
	
	얼마나 `x`를 넣으면 얼마나 증가하는지 증가량을 그래프로도 확인 할 수 있다.

<br>

+ 정리
  
	위의 예제를 보면 2보다 적은 데이터에서는 `t(n)`을 쓰는게 나아보이기도 하고 그냥 `t1(n)`을 사용하는 것이 좋아보이고 한다. 
	
	정답은 알고리즘은 상황에 따라 사용하는 것이 옳다.
	
	절대 많은 데이터를 요구하지 않는다면 `t(n)`을 쓰는게 좋지만 그게 아닌 경우에는 `t1(n)`을 쓰는게 좋을 수 있다.
	
	즉, 알고리즘에는 무조건 사용해야하는 알고리즘만이 존재하는 것은 아니다. 대체로 십중 팔구 특정 알고리즘을 사용해야 쉽게 풀리는 문제들로 구성되는 경우가 대다수이긴 하지만 면접관 입장에서는 고지식하게 "_이거만 써야한다!_"라는 답만을 외치는 개발자는 별로 좋게 생각하진 않는다. 
	==기초지식과 더불어 얼마나 유연하고 융통성있게 문제를 대처하는지도 평가항목이다.==

<br>

### 시간 복잡도와 공간복잡도의 중요성

==**이 시간&공간 복잡도 분석능력은 무조건 함양해야 할 개발자 필수 능력이다.**==

대부분의 테크 기업은 이 능력으로 개발자의 기본 능력치를 평가하며 이는 당연한 것이다.
마치 구구단을 9단까지 제대로 외웠는지 평가하는 수준이라고도 말해도 되는 수준이다.(그정도로 그냥 당연히 잘해야하는 공부영역이라는 뜻)

이를 제대로 갈고 닦은 개발자가 제시한 문제(앞으로 처리해야 할 각종 비즈니스 도메인)를 제대로 이해하고 분석하고 풀어내는 능력이 있다는 것을 여실히 증명하기 때문이다.

정리하자면, 개발에 관심이 있다면 이 능력은 무조건 갈고 닦아야한다. 

<br>

### 예제 - 순차 탐색과 시간 복잡도 분석의 핵심요소

``` CPP
#ifndef FIRSTCPP_LINEARSEARCH _H  
#define FIRSTCPP_LINEARSEARCH _H  
  
#include <iostream>  
  
int lSearch(const int array[], int length, int target){  
    for (int index = 0; index < length; ++index) {  
        if(array[index] == target){  
            return index;  
        }  
    }  
    return -1;  
}  
#endif // FIRSTCPP_LINEARSEARCH _H

#include "enthusiasm/algorithm/LinearSearch.h"  
  
int main(){  
    int array[] = {3, 5, 2, 4, 9};  
  
    int result = lSearch(array, sizeof(array) / sizeof(int), 4);  
  
    if(result == -1){  
        std::cout<<"탐색 실패!"<<std::endl;  
    }else{  
        std::cout<<"타겟 저장 인덱스: "<<result<<std::endl;  
    }  
  
    result = lSearch(array, sizeof(array) / sizeof(int), 7);  
  
    if(result == -1){  
        std::cout<<"탐색 실패!"<<std::endl;  
    }else{  
        std::cout<<"타겟 저장 인덱스: "<<result<<std::endl;  
    }  
      
    return 0;  
}
```

+ 설명

	 여기에서 주요 알고리즘인 탐색 알고리즘에서 쓰인 연산은 총 3 가지이다.
	 `<`, `++`, `==`  
	 이 연산자들이 얼마나 많이 사용이 되었는가를 분석하는 것이 기초적인 복잡도 분석 방법이다.
	 
	 여기서 좋은 탐색 알고리즘의 핵심은 주로 `==` 연산을 얼마나 적게 했는가?이다.
	 
	 `==` 연산을 적게해야 `<`, `++` 연산을 뒤이어서 하지 않기 때문이다.
	 
	 즉, 이 탐색 알고리즘은 == 연산에 의존적이니 --연산 횟수를 대상으로 시간 복잡도를 분석하면 된다.
	 
	 이렇게 **==알고리즘의 시간 복잡도는 핵심이 되는 연산이 무엇인지를 알아야한다.==**
	 
	 그리고 이 알고리즘에는 최선의 case와 최악의 케이스가 있다.
	 타겟이 배열의 앞에 있을 수록 최선의 case이며 최악에 케이스는 맨 뒤에 있는 경우이다.
	 
	 즉, 모든 알고리즘에는 최선, 최악의 케이스가 존재한다.
	 이때 최악의 케이스를 중요하게 따져야한다.
	 
	 이때, 평균 케이스를 구하면 되지 않느냐? 라고 생각할 수 있겠지만 실제로는 정확한 평균을 구하기 위해서는 광범위한 데이터를 넣어보아야하기 때문에 일반적으로 최악의 case를 기준으로 삼는다.
	 
	 참고로 이것을 정확히 캐치하는 것이 코딩테스트 심사평가에 주요요소이다.

### 순차 탐색 알고리즘 시간복잡도 계산하기, worst case

이 순차 탐색 알고리즘은 맨 뒤에 위치한 경우가 최악의 경우이므로

n만큼 소모되어야 최악이다.

즉, `T(n) = n`이다.

### 순차 탐색 알고리즘 시간복잡도 계산하기, average case

가정 1) 탐색 대상이 배열에 존재하지 않을 확률 50%

가정 2) 배열의 첫 요소부터 끝 요소까지 탐색 대상이 존재할 확률이 동일함

이런 가정하에 배열에 탐색 대상이 존재하는 경우와 존재하지 않은 경우를 나눠서 계산해보자 
+ 배열에 탐색 대상이 존재하지 않는 경우 
	
	무조건 존재하지 않으면 끝까지 탐색을 해야하므로 n이다.

<br>

+ 배열에 탐색 대상이 존재하는 경우의 연산 횟수
	맨 처음 요소에 존재하는 경우 비교 연산 횟수는 1, 맨 마지막일 경우는 n이다.
	
	만약 길이가 9의 배열일 경우는 맨 처음일 경우는 1, 맨 마지막의 경우는 9이다.
	
	즉 모든 요소에 평균적인 연산횟수값은 배열의 모든 요소 비교 횟수 값은 최대 값에 나누기를 2하면 평균일태니 배열에 탐색 대상이 존재하는 경우는 n/2라고 할 수 있겠다.

<br>

+ 정리
	여기서 탐색 대상이 존하는 경우와 존재하지 않을 확률이 각각 50%이니 식을 묶어야한다.
	
	`n * 1/2 + n/2 * 1/2 = 3/4 * n`
	
	여기서 `1/2`씩 곱한 이유는 존재할 확률과 없을 확률이 각각 50%이기 때문
	
	`n * 1/2`은 아예 존재하지 않을 확률, `n/2 * 1/2`은 존재할 확률이다.
	
	즉, 평균적인 시간 복잡도는 `3/4*n`이다.

## 이진 탐색 알고리즘 소개

순차 탐색보다 월등히 성능이 좋은 알고리즘이다.

다만 배열의 요소가 순차적으로 정렬이 된 상태이여야한다는 조건이 존재한다.

이 조건이 없으면 이진 탐색은 불가능하다.

### 예시

1, 2, 3, 7, 9, 12, 21, 23, 27

이렇게 초기화된 배열이 있다. 이 배열을 대상으로 숫자 3이 저장되어있는지 찾는 알고리즘은 다음과 같다.

<br>

+ 알고리즘 실행 과정 Ⅰ
	1. 배열 인덱스의 시작과 끝은 0, 8이다.
	2. 0과 8을 합하여 그 결과를 2로 나눈다.
	3. 2로 나눈 결과 4를 인덱스 값으로 하여 4번 인덱스에 저장된 값이 3인지 확인한다.
	   
	즉, **배열의 중앙에 찾는 값이 저장되어있는지 확인**하는 것이 맨 처음 로직이다.

<br>

+ 알고리즘 실행과정 Ⅱ
	1. 4번째 인덱스에 3이 저장되지 않았으니 저장된 값 9와 3의 대소를 비교한다.
	2. 대소 비교결과는 3이 더 작으니 탐색 범위를 0~3까지로 제한한다.
	3. 0과 3을 더하여 그 결과를 2로 나눈다.
	4. 2로 나눈 결과 1을 인덱스 값으로 하여 1번 인덱스에 저장된 값이 3인지 확인한다.
	   
	여기서 주목할 점은 배열의 탐색 범위를 반으로 줄여버렸다. 이는 배열이 정렬된 상태이기 때문에 가능하다. 그래서 이진 탐색 알고리즘은 정렬이 필수이다.

<br>

+ 알고리즘 실행과정 Ⅲ
	1. 1번 인덱스에 저장된 값 2와 3의 대소를 비교한다.
	2. 대소 비교결과는 2가 더 작으니 탐색 범위를 2~3까지 제한한다.
	3. 2와 3을 더해 그 결과를 2로 나눈다.
	4. 2로 나눈 결과 2를 인덱스 값으로 하여 2번 인덱스에 저장된 값이 3인지 확인한다.
	   
	즉, 2번 실행과정을 기점으로 계속 반복해서 대소를 비교, 탐색범위 제한, 비교 대상 선정, 저장된 값 확인 이것을 찾을 때까지 반복한다.


<br>

### 이진 탐색 알고리즘의 구현

+ 알고리즘의 반복 조건
	
	이 알고리즘은 언제까지 반복되어야 하는지 알아야한다.
	
	핵심은 탐색 범주의 first 인덱스와 last 인덱스의 대소 비교이다.
	
	다시 말해 first 인덱스가 last 인덱스보다 **작거나 같은 경우**에만 비교를 해야한다


<br>

### 예제

``` cpp
#ifndef FIRSTCPP_BINARYSEARCH _H  
#define FIRSTCPP_BINARYSEARCH _H  
#include <iostream>  
  
int bSearch(const int arr[], int length, int target) {  
    int first = 0;  
    int last = length - 1;  
    int mid;  
  
    while(first <= last){  
        mid = (first + last) / 2;  
  
        if(target == arr[mid]){  
            return mid;  
        }else{  
            if(target < arr[mid]){  
                last = mid - 1;  
            }else{  
                first = mid + 1;  
            }  
        }  
    }  
    return -1;  
}  
#endif // FIRSTCPP_BINARYSEARCH _H

#include "enthusiasm/algorithm/BinarySearch.h"  
  
int main(){  
    int array[] = {1, 3, 5, 7, 9};  
    int result = bSearch(array, sizeof(array) / sizeof(int), 7);  
  
    if(result == -1){  
        std::cout<<"탐색 실패!"<<std::endl;  
    }else{  
        std::cout<<"타겟 저장 인덱스: "<<result<<std::endl;  
    }  
  
    result = bSearch(array, sizeof(array) / sizeof(int), 4);  
  
    if(result == -1){  
        std::cout<<"탐색 실패!"<<std::endl;  
    }else{  
        std::cout<<"타겟 저장 인덱스: "<<result<<std::endl;  
    }  
    return 0;  
}
```

+ 설명
	
	위의 예제를 보게되면 `last`나 `first`에 `mid`를 직접 대입하지 않고 1씩 증가시키는데 이유는 탐색 대상이 존재하지 않는 경우 때문에 그렇다.
	
	탐색 대상이 배열에 존재하지 않는 경우  **`first`에 저장된 값이 `last`보다 커져서 반복문을 탈출해야하지만 `mid`를 직접 대입하는 경우 `first`에 저장된 값은 `last`보다 커질 수가 없다.** 
	
	간단히 생각해보면 늘 `mid`는 `first`보다 작다. 이러면 당연히 직접 `mid`를 대입하는 순간 무한 루프의 문제가 발생하게 되는 것이다.


<br>

### 이진 탐색 알고리즘의 시간 복잡도 계산하기, worst case

탐색 대상의 데이터 수가 n개로부터 시작해 반씩 줄어 마지막에는 1개가 된다.
반씩 줄어드는 과정을 몇 번 거치는지 알 수 없다는 것이 문제이다.

여기서 식을 하나 세워보자

n이 1이 되기까지 2로 나눈 횟수 k회, 따라서 비교 연산 k회 진행, 

데이터가 1개 남았을 때, 이때 마지막 비교연산 1회 진행

∴ 최악의 경우에 대한 시간 복잡도 함수는 `T(n) = k + 1`

여기서 n이 1이 될때까지 2로 k번 나눈 것이니 n과 k의 관계는 다음과 같다.  

$$
\begin{flalign}
n * (1/2)^k = 1
\end{flalign}
$$

이 식을 정리 해보자.
$$
\begin{flalign}
n * (\frac{1}{2})^k &= 1 \\
n * 2^{-k} &= 1 \\
∴ n &= 2^k
\end{flalign}
$$
여기서 양 변에 밑이 2인 로그를 취하게 해보자.
$$
\begin{flalign}
n &= 2^{k} \\
log_{2}n &= log_{2}2^{k} &∵log_{a}b^{k} &= klog_{a}b \\
log_{2}n &= klog_{2}2 \\
log_{2}n &= k &∵log_{a}a &= 1\\
\end{flalign}
$$

즉 `k`는` log_{2}n`이다.

따라서 `T(n) = log_{2}n`이다.

그러나 여기에서 분명 `T(n) = k + 1`이니 치환하면 `log_{2}n + 1`아닌가? 할 수 있다.

그러나 중요한 것은 `+1` 은 중요하지 않다. 

**==중요한 것은 데이터의 수 `n`이 증가함에 따라서 비교연산의 횟수가 로그적으로 증가한다는 사실이 핵심==**이다.

앞서 식을 구성하면 데이터 수의 증가에 따른 연산횟수의 변화량을 분석할 수 있다고 했다.

즉, ==n에 대한 식 T(n)은 데이터 수의 증가에 따른 연산횟수의 변화량을 판단하는 것이므로 + 1은 중요하지 않다.==

따라서 +1은 중요하지 않다는 의미인데 여기서 **빅-오 표기법**을 반드시 알아둬야한다.

### 빅-오 표기법, Big-Oh Notation

> 빅-오란 함수 T(n)에서 가장 영향력이 큰 부분이 어디인지를 따지는 것이며 이에 사용하는 표기법에 대문자 O가 사용되기 때문에 빅-오라고 한다.

$$\begin{flalign}
T(n) &= n^{2}+ 2n + 1&
\end{flalign}$$

다음과 같은 시간 복잡도 함수가 있을 때, **근사치(approximation)식**을 구성하면 다음과 같다.

$$
\begin{flalign}
T(n) &= n^{2}+ 2n&
\end{flalign}
$$

여기서 한번 더 간략화를 진행하면

$$
\begin{flalign}
T(n) &= n^{2}&
\end{flalign}
$$

다음과 같다.

물론 "_과감히 `2n`을 빼도 되나?_" 싶을 수도 있지만

데이터의 수 `n`의 호출 횟수를 10~100000까지 비교를 해보면 다음과 같다.

|       `n `|            `n^2` |      `2n` |           `T(n)` | `n^2`의 비율 |
| -------:| --------------:| -------:| --------------:| ----------:|
|      10 |            100 |      20 |            120 |     83.33% |
|     100 |         10,000 |     200 |         10,200 |     98.04% |
|   1,000 |      1,000,000 |   2,000 |      1,002,000 |     99.80% |
|  10,000 |    100,000,000 |  20,000 |    100,020,000 |     99.98% |
| 100,000 | 10,000,000,000 | 200,000 | 10,000,200,000 |     99.99% |

즉, `n^2`가 차지하는 비율은 100회부터 98%를 차지한다. 따라서 `n^2`로 **간략화 한 것이 빅-오**이며 이것을 빅-오 표기법으로 표기하면 다음과 같다.

$$
\begin{flalign}
&O(n^2) &
\end{flalign}
$$
읽는 방법은 _"빅-오 오브 n^2(Big-Oh of n^2)"_ 이다.

이는 n의 증가 및 감소에 따른 `T(n)`의 변화 정도가 `n^2` 형태를 띄는 것을 의미한다.

### 빅-오 구하는 간단 방법

결국 핵심은 T(n)을 간략화해야하는 것이 빅-오의 핵심이며 T(n)이 다항식인 경우 **최고차항의 차수를 구하면 된다.**

+ 예시
1. T(n) = n^2 + 2n + 9
T(n) = n^2

2. T(n) = n^4 + n^3 + n^2 + 1
T(n) = n^4

3. T(n) = 5n^3 + 3n^2 + 2n + 1
T(n) = n^3

이 예시를 토대로 일반화를 진행하면 다음과 같다.

$$
\begin{align*}
T(n) = a_{m}n^{m} + a_{m-1}n^{m-1} + a_{m-2}n^{m-2} + ... + a_{1}n^{1} + a_{0} \\
\Downarrow \\
∴ O(n^{m})
\end{align*}
$$

즉,  ==T(n)에서 의미가 있는 것은최고차항의 차수뿐이라는 의미==이다.

핵심은 데이터 수의 증가에 따른 연산횟수의 증가형태(패턴)을 나타내는 표기법이다.

즉, 핵심 연산의 호출 횟수가 중요하다.

### 예제 - 빅-오 구하기

1. 3n + 2
$$
\begin{flalign}
&O(n)&
\end{flalign}
$$

2. 7n^3 + 3n^2 + 2
$$
\begin{flalign}
&O(n^3)&
\end{flalign}
$$
3. 2^n + n^2
$$
\begin{flalign}
&O(2^n)&
\end{flalign}
$$
4. n + logn
$$
\begin{flalign}
&O(n)&
\end{flalign}
$$
5. n + nlogn
$$
\begin{flalign}
&O(nlogn)&
\end{flalign}
$$
6. 2^n + n^3
$$
\begin{flalign}
&O(2^n)&
\end{flalign}
$$


### 대표적인 빅-오

+ `O(1)`
상수형 빅오라고 부르며 데이터수와 상관없이 연산횟수가 고정적인 유형의 알고리즘을 의미한다.
예를 들면 데이터가 아무리 많아도 연산 횟수가 단 3번이면 O(3) 이다. 이렇게 연산 횟수가 고정인 유형을 의미한다. 참고로 해시 테이블의 데이터 탐색 속도가 대표적인 상수 연산횟수를 자랑하는 상수형 빅-오이다.

+ `O(logn)`
로그형 빅-오라 부르며 데이터 수의 증가율에 비해 연산 횟수의 증가율이 훨씬 낮은 알고리즘을 의미한다. 즉, 이 로그형 빅-오가 이상적인 알고리즘이라고 할 수 있다. 참고로 로그의 밑이 얼마인지 중요하지 않다. 알고리즘 성능관점에서 매우 미미하기 때문에 대부분의 경우 밑은 무시된다. 참고로 이진탐색 알고리즘이 대표적인 로그형 빅-오 알고리즘이다.

+ `O(n)`
이는 선형 빅-오라고 부른다. 데이터의 수와 연산횟수가 비례하는 알고리즘을 의미하며 일반적인 포문 하나만 사용한 연산의 경우 선형 빅-오 형태를 띈다.

+ `O(nlogn)`
이는 선형로그형 빅-오라고 부른다. 이는 데이터의 수가 두 배로 늘 때, 연산횟수는 두 배를 조금 넘게 증가하는 알고리즘을 의미한다. n과 logn을 곱한 형태이지만 대부분 알고리즘은 이 선형로그형 빅-오 형태를 띄고 있다.

+ `O(n^2)`
이는 데이터 수의 제곱에 해당하는 연산횟수를 요구하는 알고리즘을 의미한다. 포문 2개를 중첩시키면 이와 같은 형태를 가지게 된다. 즉, 만약 알고리즘에 중첩포문 형태를 가진다면 이는 딱히 바람직한 알고리즘이 아니라는 의미이다.

+ `O(n^3)`
이는 데이터 수의 제곱에 해당하는 연산횟수를 요구하는 알고리즘을 의미한다. 포문 3개를 중첩시키면 이와 같은 형태를 가지게 된다. 다시 말하지만, 만약 알고리즘에 중첩포문 형태를 가진다면 이는 딱히 바람직한 알고리즘이 아니라는 의미이다.

+ `O(2^n)`
이는 지수형 빅-오라고 부르며  사용하기에 매우 위험한, 사용하려는 것 자체가 비현실적인 알고리즘이다.
지수적 증가라는 것은 매우 무서운 연산횟수 증가를 의미하기 때문이다. 우연이라도 이러한 성능을 지닌 알고리즘을 만들었다면 반드시 수정해야한다.

### 대표적인 빅-오 비교

$$
\begin{flalign}
O(1)<O(logn)<O(n)<O(nlogn)<O(n^2)<O(n^3)<O(2^n)
\end{flalign}
$$
빅-오 표기들의 성능(수행시간, 연산횟수)의 대소를 정리하면 이렇게 된다.

그래프로 표현해보자.

```mathpad
%$2:=x
%$3:=log(x)
%$4:=x
%$5:=x
%$6:=x^2
%$7:=x^3
%$8:=2^x
O1(n):=x
O2(n):=log(x)
O3(n):=x
O4(n):=x*log_{x}
O5(n):=x^2
O6(n):=x^3
O7(n):=2^x
plot(O2(n), O3(n), O4(n), O5(n), O6(n), O7(n), [0,10])=~?
```

<br>

### 순차 탐색 알고리즘과 이진 탐색 알고리즘의 비교

+ T(n) 비교

	+ 순차 탐색 알고리즘
		T(n) = n
	+ 이진 탐색 알고리즘
		T(n) = log_{2}n + 1


+ 빅-오 비교

	+ 순차 탐색 알고리즘
		O(n)
	+ 이진 탐색 알고리즘
		O(logn)

즉, 이진 탐색 알고리즘이 압도적으로 성능이 좋다.


<br>

### 예제

``` cpp
#ifndef FIRSTCPP_BSWORSTOPCOUNT _H  
#define FIRSTCPP_BSWORSTOPCOUNT _H  
#include <iostream>  
  
int bSearch(const int arr[], int length, int target) {  
    int first = 0;  
    int last = length - 1;  
    int mid;  
    int opCount = 0;  
  
    while(first <= last){  
        mid = (first + last) / 2;  
  
        if(target == arr[mid]){  
            return mid;  
        }else{  
            if(target < arr[mid]){  
                last = mid - 1;  
            }else{  
                first = mid + 1;  
            }  
        }  
        ++opCount;  
    }  
    std::cout<<"비교연산횟수: "<<opCount<<std::endl;  
    return -1;  
}  
#endif // FIRSTCPP_BSWORSTOPCOUNT _H

#include "enthusiasm/algorithm/BSWorstOpCount.h"  
  
int main(){  
    int arr1[500] = {0,};  
    int arr2[5000] = {0,};  
    int arr3[50000] = {0,};  
    int result;  
  
    result = bSearch(arr1,sizeof(arr1)/sizeof(int), 1);  
  
    if(result == -1){  
        std::cout<<"탐색 실패"<<std::endl<<std::endl;  
    }else{  
        std::cout<<"타겟 저장 인덱스: "<<result<<std::endl;  
    }  
  
    result = bSearch(arr2,sizeof(arr2)/sizeof(int), 2);  
  
    if(result == -1){  
        std::cout<<"탐색 실패"<<std::endl<<std::endl;  
    }else{  
        std::cout<<"타겟 저장 인덱스: "<<result<<std::endl;  
    }  
  
    result = bSearch(arr3,sizeof(arr3)/sizeof(int), 3);  
  
    if(result == -1){  
        std::cout<<"탐색 실패"<<std::endl<<std::endl;  
    }else{  
        std::cout<<"타겟 저장 인덱스: "<<result<<std::endl;  
    }  
  
    return 0;  
}
```

+ 설명

	|  `n`   | 순차 탐색 알고리즘 | 이진 탐색 알고리즘 |
	|:------:|:------------------:|:------------------:|
	|  500   |        500         |         9          |
	| 5,000  |       5,000        |         13         |
	| 50,000 |       50,000       |         16         |


## 빅-오의 수학적 판별법

> 두 개의 함수 `f(n)`과 `g(n)`이 주어졌을 때, 모든 `n ≥ K`에 대하여 `f(n) ≤ Cg(n)`을 만족하는 두 개의 상수 `C`와 `K`가 존재하면, `f(n)`의 빅-오는 `O(g(n))`이다.

<br>

###  설명

+ f(n)
	5n^2 + 100

<br>

+ g(n)
	n^2

이 상황에서 `f(n) ≤ Cg(n)`이 만족해야한다. 단, n ≥ 12 이여야한다.

이때 C에 3500을 넣어보면 위의 항등식은 `5n^2 + 100 ≤ 3500n^2`로 항상 성립한다.

즉 정리해보자면 다음과 같다.

두 개의 함수 `f(n) = 5n^2 + 100`과 `g(n) = n^2`이 주어졌을 때, 모든 `n ≥ 12`에 대하여 `5n^2 + 100 ≤ 3500n^2`를 만족하는 3500(C)과 12(K)가 존재하니 `5n^2 + 100`의 빅-오는 `O(n^2)`이다.

이 판별법의 핵심 내용은 다음과 같다. 

n은 계속 커지는 숫자이며 `n ≥ 12`를 기점으로 `f(n) ≤ Cg(n)`가 항상 성립한다. **==따라서 K는 아무리 크게 잡아서 상관이 없는 이유는 `f(n) = 5n^2 + 100`기준으로 증가율 패턴이 n^2을 넘지 못한다는 의미==**이다.

즉, 빅오는 지금까지 데이터 수의 증가에 따른 연산횟수의 증가 형태를 표현한 것이였지만 수학식 판별법에 따르면 데이터 수의 증가에 따른 연산횟수의 증가율 상한선을 표현한 것으로 바뀌게 된다.

이 두개의 정리는 연관이 있는데 연산횟수의 증가율 상한선이 n^2인 경우, 연산횟수의 증가 형태는 n^2 형태(패턴)을 못 벗어나기 때문이다. 즉, n^2의 증가 패턴이 기준이 되는 것이다.

참고로 `n`과 `f(n)`과 `g(n)`은 0이상이다.

`n ≥ 0, f(n) ≥ 0, g(n) ≥ 0` 이 조건이 필수로 초기에 붙어야한다.

### 예시, 빅-오의 증명

**다음 주어지는 T(n)과 그 식의 빅-오 판별 결과가 옳음을 빅-오의 수학적인 정의를 근거로 정의해보시오.**

1. `T(n) = 3n + 2` => `O(n)`
	`n ≥ K, T(n) ≤ Cg(n)`과 같은 상황에서 `C`와 `K`가 존재함을 증명하면된다.

$$
\begin{flalign}
T(n) = 3n + 2, g(n) = n \\
if\hspace{0.75em} (n ≥ 1, C = 5) 3n + 2 &≤ 5n \\
∴ C = 5, K = 1
\end{flalign}
$$
`C = 5`,  `K = 1`이면 항상 성립하니 `C`와 `K`가 존재한다.
따라서 `O(n)`의 패턴을 벗어나지 않음으로 `T(n) = 3n + 2` 의 빅-오는 `O(n)`이다.


2. `T(n) = 7n^3 + 3n^2 + 2` => `O(n^3)`
	`n ≥ K, T(n) ≤ Cg(n)`과 같은 상황에서 `C`와 `K`가 존재함을 증명하면된다.

$$
\begin{flalign}
T(n) = 7n^3 + 3n^2 + 2, g(n) = n^3 \\
if\hspace{0.75em} (n ≥ 2, C = 9) 7n^3 + 3n^2 + 2, &≤ 9n^3 \\
∴ C = 9, K = 2
\end{flalign}
$$

`C = 9`,  `K = 2`이면 항상 성립하니 `C`와 `K`가 존재한다.
따라서 `O(n^3)`의 패턴을 벗어나지 않음으로 `T(n) = 7n^3 + 3n^2 + 2` 의 빅-오는 `O(n^2)`이다.
